# -*- coding: utf-8 -*-
"""Assigmetn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IplQuwtO7xYDh103YWcAMeGXBqKPpYt8
"""

import tensorflow as tf
import tensorflow_datasets as tfds
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, f1_score
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.mixed_precision import set_global_policy
import os

# Mixed precision training uchun sozlash
set_global_policy('mixed_float16')

# Fayl tuzilmasini yaratish
os.makedirs('output', exist_ok=True)

print("Kutubxonalar muvaffaqiyatli yuklandi!")

# 1. Datasetni yuklash va tayyorlash (train, val, test sifatida uchtaga bo'linadi)
def load_and_preprocess_data(image_size=(128, 128), batch_size=32):
    print("Dataset yuklanmoqda...")
    # Datasetni 70% (train), 20% (val), 10% (test) sifatida bo'lamiz
    (ds_train, ds_val, ds_test), ds_info = tfds.load(
        'malaria',
        split=['train[:70%]', 'train[70%:90%]', 'train[90%:]'],
        as_supervised=True,
        with_info=True
    )

    def preprocess_image(image, label):
        image = tf.cast(image, tf.float32) / 255.0
        image = tf.image.resize(image, image_size)
        image = tf.image.adjust_contrast(image, 1.1)
        return image, tf.cast(label, tf.float32)

    def augment_image(image, label):
        image = tf.image.random_flip_left_right(image)
        image = tf.image.random_flip_up_down(image)
        image = tf.image.random_brightness(image, max_delta=0.2)
        image = tf.image.random_contrast(image, lower=0.8, upper=1.2)
        image = tf.image.random_hue(image, max_delta=0.05)
        image = tf.clip_by_value(image, 0.0, 1.0)
        return image, label

    print("Dataset preprocessing...")
    ds_train = ds_train.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)
    ds_train = ds_train.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)
    ds_train = ds_train.cache().shuffle(2000).batch(batch_size).prefetch(tf.data.AUTOTUNE)

    ds_val = ds_val.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)
    ds_val = ds_val.batch(batch_size).prefetch(tf.data.AUTOTUNE)

    ds_test = ds_test.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)
    ds_test = ds_test.batch(batch_size).prefetch(tf.data.AUTOTUNE)

    print("Dataset tayyorlandi!")
    return ds_train, ds_val, ds_test, ds_info

# Dataset namunalarini vizualizatsiya qilish
def visualize_samples(ds, ds_info, output_dir='output'):
    print("Namunaviy tasvirlar vizualizatsiya qilinmoqda...")
    plt.figure(figsize=(10, 10))
    for i, (image, label) in enumerate(ds.unbatch().take(9)):
        plt.subplot(3, 3, i + 1)
        plt.imshow(image.numpy())
        plt.title(f"Label: {'Infected' if label.numpy() == 1 else 'Uninfected'}")
        plt.axis('off')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'sample_images.png'))
    plt.close()
    print("Namunaviy tasvirlar saqlandi!")

# 2. CNN modelini yaratish
def create_cnn_model(image_size=(128, 128, 3)):
    print("CNN model yaratilmoqda (yana optimallashtirilgan)...")
    model = models.Sequential([
        layers.Input(shape=image_size),
        layers.RandomRotation(factor=0.2, fill_mode='nearest'),

        # 1-chi blok
        layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
        layers.BatchNormalization(),
        layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.2),

        # 2-chi blok
        layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
        layers.BatchNormalization(),
        layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.25),

        # 3-chi blok
        layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
        layers.BatchNormalization(),
        layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.3),

        # 4-chi blok
        layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
        layers.BatchNormalization(),
        layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='last_conv_layer', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
        layers.BatchNormalization(),
        layers.MaxPooling2D((2, 2)),
        layers.Dropout(0.4),

        # Final qism
        layers.Flatten(),
        layers.Dense(256, activation='relu'),
        layers.BatchNormalization(),
        layers.Dropout(0.4),
        layers.Dense(1, activation='sigmoid', dtype='float32')
    ])

    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002),
        loss='binary_crossentropy',
        metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]
    )

    print("Model yaratildi va compile qilindi!")
    return model

# 3. Modelni o'qitish
def train_model(model, ds_train, ds_val, epochs=20):
    print("Model o'qitish boshlanmoqda...")
    callbacks = [
        EarlyStopping(monitor='val_accuracy', patience=10, min_delta=0.001, restore_best_weights=True),
        ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, min_lr=1e-6),
        ModelCheckpoint('output/malaria_cnn_best.h5', save_best_only=True, monitor='val_accuracy'),
        tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.0002 * (0.5 ** (epoch // 5)))
    ]

    history = model.fit(
        ds_train,
        validation_data=ds_val,
        epochs=epochs,
        callbacks=callbacks,
        verbose=1
    )
    print("Model o'qitish tugallandi!")
    return history

# 4. Modelni baholash va vizualizatsiya (val va test datasetlari uchun)
def evaluate_and_visualize(model, ds_val, ds_test, history, output_dir='output'):
    # Validation dataseti uchun baholash
    print("Validation dataseti uchun model baholanmoqda...")
    val_loss, val_accuracy, val_precision, val_recall, val_auc = model.evaluate(ds_val)
    print(f"Validation Loss: {val_loss:.4f}")
    print(f"Validation Accuracy: {val_accuracy:.4f}")
    print(f"Validation Precision: {val_precision:.4f}")
    print(f"Validation Recall: {val_recall:.4f}")
    print(f"Validation AUC: {val_auc:.4f}")

    # Test dataseti uchun baholash
    print("\nTest dataseti uchun model baholanmoqda...")
    test_loss, test_accuracy, test_precision, test_recall, test_auc = model.evaluate(ds_test)
    print(f"Test Loss: {test_loss:.4f}")
    print(f"Test Accuracy: {test_accuracy:.4f}")
    print(f"Test Precision: {test_precision:.4f}")
    print(f"Test Recall: {test_recall:.4f}")
    print(f"Test AUC: {test_auc:.4f}")

    # Validation dataseti uchun bashoratlar
    print("\nValidation dataseti uchun bashoratlar olinmoqda...")
    y_pred_val = []
    y_true_val = []
    y_scores_val = []
    for image, label in ds_val.unbatch().take(1000):
        pred = model.predict(image[None, ...], verbose=0)
        y_scores_val.append(pred[0])
        # Bashoratni teskari qilamiz
        predicted_label = int(pred[0] > 0.5)
        predicted_label = 1 - predicted_label  # 0 ni 1 ga, 1 ni 0 ga o'zgartiramiz
        y_pred_val.append(predicted_label)
        y_true_val.append(label.numpy())

    # Validation F1-score
    f1_val = f1_score(y_true_val, y_pred_val)
    print(f"Validation F1-Score: {f1_val:.4f}")

    # Test dataseti uchun bashoratlar
    print("\nTest dataseti uchun bashoratlar olinmoqda...")
    y_pred_test = []
    y_true_test = []
    y_scores_test = []
    for image, label in ds_test.unbatch().take(500):
        pred = model.predict(image[None, ...], verbose=0)
        y_scores_test.append(pred[0])
        # Bashoratni teskari qilamiz
        predicted_label = int(pred[0] > 0.5)
        predicted_label = 1 - predicted_label  # 0 ni 1 ga, 1 ni 0 ga o'zgartiramiz
        y_pred_test.append(predicted_label)
        y_true_test.append(label.numpy())

    # Test F1-score
    f1_test = f1_score(y_true_test, y_pred_test)
    print(f"Test F1-Score: {f1_test:.4f}")

    # Validation Chalkashlik matritsasi
    print("\nValidation Chalkashlik matritsasi vizualizatsiyasi...")
    cm_val = confusion_matrix(y_true_val, y_pred_val)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues', xticklabels=['Uninfected', 'Infected'], yticklabels=['Uninfected', 'Infected'])
    plt.title('Validation Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.savefig(os.path.join(output_dir, 'val_confusion_matrix.png'))
    plt.close()

    # Test Chalkashlik matritsasi
    print("Test Chalkashlik matritsasi vizualizatsiyasi...")
    cm_test = confusion_matrix(y_true_test, y_pred_test)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', xticklabels=['Uninfected', 'Infected'], yticklabels=['Uninfected', 'Infected'])
    plt.title('Test Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.savefig(os.path.join(output_dir, 'test_confusion_matrix.png'))
    plt.close()

    # Validation ROC Curve
    print("Validation ROC Curve vizualizatsiyasi...")
    fpr_val, tpr_val, _ = roc_curve(y_true_val, y_scores_val)
    roc_auc_val = auc(fpr_val, tpr_val)
    plt.figure(figsize=(8, 6))
    plt.plot(fpr_val, tpr_val, label=f'ROC curve (AUC = {roc_auc_val:.2f})')
    plt.plot([0, 1], [0, 1], 'k--')
    plt.title('Validation Receiver Operating Characteristic (ROC)')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend(loc='lower right')
    plt.savefig(os.path.join(output_dir, 'val_roc_curve.png'))
    plt.close()

    # Test ROC Curve
    print("Test ROC Curve vizualizatsiyasi...")
    fpr_test, tpr_test, _ = roc_curve(y_true_test, y_scores_test)
    roc_auc_test = auc(fpr_test, tpr_test)
    plt.figure(figsize=(8, 6))
    plt.plot(fpr_test, tpr_test, label=f'ROC curve (AUC = {roc_auc_test:.2f})')
    plt.plot([0, 1], [0, 1], 'k--')
    plt.title('Test Receiver Operating Characteristic (ROC)')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.legend(loc='lower right')
    plt.savefig(os.path.join(output_dir, 'test_roc_curve.png'))
    plt.close()

    # Model Accuracy vizualizatsiyasi
    print("Model Accuracy vizualizatsiyasi...")
    plt.figure(figsize=(8, 6))
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Model Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.savefig(os.path.join(output_dir, 'model_accuracy.png'))
    plt.close()

    # Model Loss vizualizatsiyasi
    print("Model Loss vizualizatsiyasi...")
    plt.figure(figsize=(8, 6))
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Model Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig(os.path.join(output_dir, 'model_loss.png'))
    plt.close()

    # Classification Report
    print("\nValidation Classification Report:")
    print(classification_report(y_true_val, y_pred_val, target_names=['Uninfected', 'Infected']))
    print("\nTest Classification Report:")
    print(classification_report(y_true_test, y_pred_test, target_names=['Uninfected', 'Infected']))

    return y_true_val, y_pred_val, y_scores_val, y_true_test, y_pred_test, y_scores_test

# 5. Soddalashtirilgan Grad-CAM vizualizatsiyasi
def make_gradcam_heatmap(img_array, model, last_conv_layer_name):
    try:
        last_conv_layer = model.get_layer(last_conv_layer_name)
        grad_model = tf.keras.Model(
            inputs=model.input,
            outputs=[last_conv_layer.output, model.output]
        )

        with tf.GradientTape() as tape:
            conv_outputs, predictions = grad_model(img_array)
            class_channel = predictions[:, 0]

        grads = tape.gradient(class_channel, conv_outputs)

        if grads is None:
            return None

        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        conv_outputs = conv_outputs[0]
        heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]
        heatmap = tf.squeeze(heatmap)
        heatmap = tf.maximum(heatmap, 0)
        heatmap = heatmap / (tf.math.reduce_max(heatmap) + 1e-10)
        return heatmap.numpy()
    except Exception as e:
        print(f"Grad-CAM heatmap yaratishda xatolik: {e}")
        return None

def visualize_gradcam(ds_val, model, last_conv_layer_name, output_dir='output', num_images=4):
    print("Grad-CAM vizualizatsiyasi boshlanmoqda...")
    ds_subset = ds_val.unbatch().take(num_images)
    images = []
    labels = []
    predictions = []

    print("Tasvirlar va bashoratlar tayyorlanmoqda...")
    for i, (image, label) in enumerate(ds_subset):
        images.append(image.numpy())
        labels.append(label.numpy())
        img_array = np.expand_dims(image.numpy(), axis=0)
        try:
            pred = model.predict(img_array, verbose=0)
            # Bashoratni teskari qilamiz
            predicted_label = 1 - (pred[0][0] > 0.5)  # 0 ni 1 ga, 1 ni 0 ga
            predictions.append(predicted_label)
        except Exception as e:
            print(f"Bashorat olishda xatolik: {e}")
            predictions.append(0.0)

    plt.figure(figsize=(15, 10))
    for i, (img, label, pred) in enumerate(zip(images, labels, predictions)):
        plt.subplot(2, num_images, i + 1)
        plt.imshow(img)
        plt.title(f"True: {'Infected' if label == 1 else 'Uninfected'}\nPred: {pred:.3f}")
        plt.axis('off')

        plt.subplot(2, num_images, num_images + i + 1)
        plt.imshow(img)
        try:
            img_array = np.expand_dims(img, axis=0)
            heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)
            if heatmap is not None:
                heatmap_resized = tf.image.resize(
                    heatmap[..., np.newaxis],
                    [img.shape[0], img.shape[1]]
                ).numpy().squeeze()
                plt.imshow(heatmap_resized, cmap='jet', alpha=0.5)
                plt.title("Grad-CAM Heatmap")
            else:
                plt.title("Grad-CAM (Failed)")
        except Exception as e:
            print(f"Tasvir {i+1} uchun Grad-CAM xatolik: {e}")
            plt.title("Grad-CAM (Error)")
        plt.axis('off')

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'gradcam_visualization.png'), dpi=150, bbox_inches='tight')
    plt.close()
    print("Grad-CAM vizualizatsiyasi tugallandi.")

# Alternativ Feature Map vizualizatsiyasi
def simple_feature_visualization(ds_val, model, output_dir='output', num_images=4):
    print("Oddiy feature map vizualizatsiyasi...")
    conv_layers = []
    for i, layer in enumerate(model.layers):
        if 'conv2d' in layer.name:
            conv_layers.append((i, layer.name))

    if not conv_layers:
        print("Conv2D qatlami topilmadi.")
        return

    last_conv_idx, last_conv_name = conv_layers[-1]
    feature_model = tf.keras.Model(
        inputs=model.input,
        outputs=model.layers[last_conv_idx].output
    )

    ds_subset = ds_val.unbatch().take(num_images)
    images = []
    labels = []

    for image, label in ds_subset:
        images.append(image.numpy())
        labels.append(label.numpy())

    plt.figure(figsize=(15, 12))
    for i, (img, label) in enumerate(zip(images, labels)):
        plt.subplot(3, num_images, i + 1)
        plt.imshow(img)
        plt.title(f"Original\n{'Infected' if label == 1 else 'Uninfected'}")
        plt.axis('off')

        img_array = np.expand_dims(img, axis=0)
        try:
            features = feature_model.predict(img_array, verbose=0)
            plt.subplot(3, num_images, num_images + i + 1)
            feature_map = features[0, :, :, 0]
            plt.imshow(feature_map, cmap='viridis')
            plt.title("Feature Map 1")
            plt.axis('off')

            plt.subplot(3, num_images, 2 * num_images + i + 1)
            feature_map = features[0, :, :, -1]
            plt.imshow(feature_map, cmap='plasma')
            plt.title("Feature Map Last")
            plt.axis('off')
        except Exception as e:
            print(f"Feature map {i+1} uchun xatolik: {e}")

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'feature_maps.png'), dpi=150, bbox_inches='tight')
    plt.close()

# 6. Deployment uchun funksiyalar
def preprocess_image(image_path, target_size=(128, 128)):
    img = tf.keras.preprocessing.image.load_img(image_path, target_size=target_size)
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0) / 255.0
    return img_array

def predict_image(model, image_path):
    img_array = preprocess_image(image_path)
    prediction = model.predict(img_array)
    # Bashoratni teskari qilamiz
    class_idx = 1 - int(prediction > 0.5)  # 0 ni 1 ga, 1 ni 0 ga o'zgartiramiz
    confidence = prediction[0][0] if class_idx == 1 else 1 - prediction[0][0]
    return ['Uninfected', 'Infected'][class_idx], confidence

# ASOSIY DASTUR
print("="*50)
print("MALARIA DETECTION CNN PROYEKTI")
print("="*50)

# Qadam 1: Datasetni yuklash va tasvirlarni vizualizatsiya qilish
print("\nQadam 1: Datasetni yuklash va tasvirlarni vizualizatsiya qilish")
ds_train, ds_val, ds_test, ds_info = load_and_preprocess_data(image_size=(128, 128), batch_size=32)
visualize_samples(ds_train, ds_info)
print("Dataset namunaviy tasvirlari saqlandi: output/sample_images.png\n")

# Qadam 2: Modelni yaratish va arxitekturani ko'rsatish
print("Qadam 2: Modelni yaratish")
model = create_cnn_model(image_size=(128, 128, 3))
model.summary()
print("\n")

# Qadam 3: Modelni o'qitish
print("Qadam 3: Modelni o'qitish")
history = train_model(model, ds_train, ds_val, epochs=60)
print("Model o'qitish tugallandi.\n")

# Qadam 4: Modelni baholash va vizualizatsiyalar
print("Qadam 4: Modelni baholash va vizualizatsiyalar")
y_true_val, y_pred_val, y_scores_val, y_true_test, y_pred_test, y_scores_test = evaluate_and_visualize(model, ds_val, ds_test, history)
print("Baholash va vizualizatsiyalar tugallandi. Natijalar saqlandi: output/\n")

# Qadam 5: Grad-CAM vizualizatsiyasi (Alternativ yechim)
print("Qadam 5: Grad-CAM vizualizatsiyasi")
try:
    visualize_gradcam(ds_val, model, last_conv_layer_name='last_conv_layer')
    print("Grad-CAM vizualizatsiyasi tugallandi. Natija saqlandi: output/gradcam_visualization.png\n")
except Exception as e:
    print(f"Grad-CAM xatolik: {e}")
    print("Alternativ Feature Map vizualizatsiyasiga o'tish...")
    try:
        simple_feature_visualization(ds_val, model)
        print("Feature Map vizualizatsiyasi tugallandi. Natija saqlandi: output/feature_maps.png\n")
    except Exception as e2:
        print(f"Feature Map vizualizatsiyasida ham xatolik: {e2}")
        print("Vizualizatsiya qismini o'tkazib yuborish...\n")

# Qadam 6: Modelni saqlash va test tasviri uchun bashorat
print("Qadam 6: Modelni saqlash va test tasviri uchun bashorat")
model.save('output/malaria_cnn_final.h5')
print("Model saqlandi: output/malaria_cnn_final.h5")

try:
    for image, _ in ds_test.unbatch().take(1):
        tf.keras.preprocessing.image.save_img('output/test_image.png', image.numpy())
    pred_class, confidence = predict_image(model, 'output/test_image.png')
    print(f"Test Image Prediction: {pred_class} with {confidence:.2%} confidence")
except Exception as e:
    print(f"Test tasvirini bashorat qilishda xatolik: {e}")

print("\n" + "="*50)
print("PROYEKT TUGALLANDI!")
print("Barcha natijalar 'output' papkasida saqlandi.")
print("="*50)


